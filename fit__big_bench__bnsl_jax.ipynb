{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU9P2NxqU4SA",
        "outputId": "1156fd27-22be-4ad5-f2f5-683b61cda7a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/google/BIG-bench.git\n",
            "  Cloning https://github.com/google/BIG-bench.git to /tmp/pip-req-build-hsmrm_q7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google/BIG-bench.git /tmp/pip-req-build-hsmrm_q7\n",
            "  Resolved https://github.com/google/BIG-bench.git to commit 092b196c1f8f14a54bbc62f24759d43bde46dd3b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Processing //tmp/pip-req-build-hsmrm_q7/bleurt/bleurt-b610120347ef22b494b6d69b4316e303f5932516.zip (from bigbench==0.0.1)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow-text>=2.6 (from bigbench==0.0.1)\n",
            "  Downloading tensorflow_text-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.6 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (2.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (1.4.0)\n",
            "Collecting black>=21.6b0 (from bigbench==0.0.1)\n",
            "  Downloading black-24.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from bigbench==0.0.1)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (0.6.2)\n",
            "Collecting immutabledict (from bigbench==0.0.1)\n",
            "  Downloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (1.25.2)\n",
            "Requirement already satisfied: pytest>=6.2.4 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (7.4.4)\n",
            "Collecting requests-unixsocket>=0.2.0 (from bigbench==0.0.1)\n",
            "  Downloading requests_unixsocket-0.3.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting RestrictedPython>=5.1 (from bigbench==0.0.1)\n",
            "  Downloading RestrictedPython-7.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (1.11.4)\n",
            "Requirement already satisfied: seaborn>=0.11.2 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (0.13.1)\n",
            "Collecting t5>=0.9.1 (from bigbench==0.0.1)\n",
            "  Downloading t5-0.9.4-py2.py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.5/164.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqio>=0.0.6 (from bigbench==0.0.1)\n",
            "  Downloading seqio-0.0.19-py3-none-any.whl (354 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.3/354.3 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.12.5 in /usr/local/lib/python3.10/dist-packages (from bigbench==0.0.1) (4.38.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black>=21.6b0->bigbench==0.0.1) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black>=21.6b0->bigbench==0.0.1)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black>=21.6b0->bigbench==0.0.1) (24.0)\n",
            "Collecting pathspec>=0.9.0 (from black>=21.6b0->bigbench==0.0.1)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black>=21.6b0->bigbench==0.0.1) (4.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black>=21.6b0->bigbench==0.0.1) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black>=21.6b0->bigbench==0.0.1) (4.10.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.4->bigbench==0.0.1) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.4->bigbench==0.0.1) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.4->bigbench==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: requests>=1.1 in /usr/local/lib/python3.10/dist-packages (from requests-unixsocket>=0.2.0->bigbench==0.0.1) (2.31.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->bigbench==0.0.1) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->bigbench==0.0.1) (3.4.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn>=0.11.2->bigbench==0.0.1) (1.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bigbench==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bigbench==0.0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bigbench==0.0.1) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bigbench==0.0.1) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bigbench==0.0.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bigbench==0.0.1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bigbench==0.0.1) (2.8.2)\n",
            "Collecting clu (from seqio>=0.0.6->bigbench==0.0.1)\n",
            "  Downloading clu-0.0.11-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.4/101.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from seqio>=0.0.6->bigbench==0.0.1) (0.4.23)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from seqio>=0.0.6->bigbench==0.0.1) (0.4.23+cuda12.cudnn89)\n",
            "Collecting pyglove (from seqio>=0.0.6->bigbench==0.0.1)\n",
            "  Downloading pyglove-0.4.4-py3-none-any.whl (577 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.8/577.8 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from seqio>=0.0.6->bigbench==0.0.1) (0.1.99)\n",
            "Collecting tfds-nightly==4.9.2.dev202308090034 (from seqio>=0.0.6->bigbench==0.0.1)\n",
            "  Downloading tfds_nightly-4.9.2.dev202308090034-py3-none-any.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.3 in /usr/local/lib/python3.10/dist-packages (from seqio>=0.0.6->bigbench==0.0.1) (3.20.3)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (0.5.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (5.9.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (1.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (4.66.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (1.14.1)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.10/dist-packages (from t5>=0.9.1->bigbench==0.0.1) (2.14.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from t5>=0.9.1->bigbench==0.0.1) (0.5.0)\n",
            "Collecting mesh-tensorflow[transformer]>=0.1.13 (from t5>=0.9.1->bigbench==0.0.1)\n",
            "  Downloading mesh_tensorflow-0.1.21-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.2/385.2 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from t5>=0.9.1->bigbench==0.0.1) (3.8.1)\n",
            "Collecting rouge-score>=0.1.2 (from t5>=0.9.1->bigbench==0.0.1)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu (from t5>=0.9.1->bigbench==0.0.1)\n",
            "  Downloading sacrebleu-2.4.1-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqio-nightly (from t5>=0.9.1->bigbench==0.0.1)\n",
            "  Downloading seqio_nightly-0.0.18.dev20240327-py3-none-any.whl (355 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.7/355.7 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.14 in /usr/local/lib/python3.10/dist-packages (from t5>=0.9.1->bigbench==0.0.1) (1.16.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (67.7.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->bigbench==0.0.1) (2.15.0)\n",
            "Collecting tensorflow>=2.6 (from bigbench==0.0.1)\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py>=3.10.0 (from tensorflow>=2.6->bigbench==0.0.1)\n",
            "  Downloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ml-dtypes~=0.3.1 (from tensorflow>=2.6->bigbench==0.0.1)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<2.17,>=2.16 (from tensorflow>=2.6->bigbench==0.0.1)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow>=2.6->bigbench==0.0.1)\n",
            "  Downloading keras-3.1.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.12.5->bigbench==0.0.1) (0.4.2)\n",
            "Requirement already satisfied: tf-slim>=1.1 in /usr/local/lib/python3.10/dist-packages (from bleurt@ file://localhost//tmp/pip-req-build-hsmrm_q7/bleurt/bleurt-b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt->bigbench==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->bigbench==0.0.1) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->bigbench==0.0.1) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->bigbench==0.0.1)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->bigbench==0.0.1)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->bigbench==0.0.1)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->bigbench==0.0.1) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->bigbench==0.0.1) (3.9.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.6->bigbench==0.0.1) (0.43.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->bigbench==0.0.1) (4.0.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow>=2.6->bigbench==0.0.1) (13.7.1)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow>=2.6->bigbench==0.0.1)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow>=2.6->bigbench==0.0.1)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1) (0.18.3)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5>=0.9.1->bigbench==0.0.1) (4.9.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn>=0.11.2->bigbench==0.0.1) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=1.1->requests-unixsocket>=0.2.0->bigbench==0.0.1) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.6->bigbench==0.0.1) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.6->bigbench==0.0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.6->bigbench==0.0.1) (3.0.1)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from clu->seqio>=0.0.6->bigbench==0.0.1) (0.8.2)\n",
            "Collecting ml-collections (from clu->seqio>=0.0.6->bigbench==0.0.1)\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docstring-parser>=0.12 (from pyglove->seqio>=0.0.6->bigbench==0.0.1)\n",
            "  Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
            "Collecting portalocker (from sacrebleu->t5>=0.9.1->bigbench==0.0.1)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->t5>=0.9.1->bigbench==0.0.1) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->t5>=0.9.1->bigbench==0.0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->t5>=0.9.1->bigbench==0.0.1) (4.9.4)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (3.18.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow>=2.6->bigbench==0.0.1) (2.1.5)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio>=0.0.6->bigbench==0.0.1) (1.0.8)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio>=0.0.6->bigbench==0.0.1) (0.2.1)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio>=0.0.6->bigbench==0.0.1) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->clu->seqio>=0.0.6->bigbench==0.0.1) (0.1.45)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow>=2.6->bigbench==0.0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow>=2.6->bigbench==0.0.1) (2.16.1)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections->clu->seqio>=0.0.6->bigbench==0.0.1) (21.6.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tfds-nightly==4.9.2.dev202308090034->seqio>=0.0.6->bigbench==0.0.1) (1.63.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow>=2.6->bigbench==0.0.1) (0.1.2)\n",
            "Requirement already satisfied: chex>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from optax->flax->clu->seqio>=0.0.6->bigbench==0.0.1) (0.1.86)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->clu->seqio>=0.0.6->bigbench==0.0.1) (1.6.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.7->optax->flax->clu->seqio>=0.0.6->bigbench==0.0.1) (0.12.1)\n",
            "Building wheels for collected packages: bigbench, bleurt, rouge-score, ml-collections\n",
            "  Building wheel for bigbench (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bigbench: filename=bigbench-0.0.1-py3-none-any.whl size=366200808 sha256=2f48ffd72e0066df0eaa59a1a6a8582605803f11c68549e28f9ee61d30b6bc35\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i60gpqf5/wheels/87/6f/82/0f7b655b5ea842e98d9d0336b0b93c5e546c21758147076692\n",
            "  Building wheel for bleurt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bleurt: filename=BLEURT-0.0.2-py3-none-any.whl size=16454005 sha256=a9d522edf102da22ec820e06c87d5b9cc47455029b7dbbf794f25024f3831cc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/65/91/85cbef8071892b9cd522f6beadfc0d1c7fc88a52aee87db05b\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=fe352fabea679b681d1e12b390d87750b16c973b6d3839186aed54b9aaaa45ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=7acaf702bf5c098824224935d7cb76ec5a4f85b3518351dcca81c8c27cc7a75a\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n",
            "Successfully built bigbench bleurt rouge-score ml-collections\n",
            "Installing collected packages: namex, xxhash, RestrictedPython, portalocker, pathspec, optree, mypy-extensions, ml-dtypes, ml-collections, mesh-tensorflow, immutabledict, h5py, docstring-parser, dill, colorama, tensorboard, sacrebleu, rouge-score, requests-unixsocket, pyglove, multiprocess, black, keras, tensorflow, datasets, tfds-nightly, tensorflow-text, bleurt, clu, seqio-nightly, seqio, t5, bigbench\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed RestrictedPython-7.1 bigbench-0.0.1 black-24.3.0 bleurt-0.0.2 clu-0.0.11 colorama-0.4.6 datasets-2.18.0 dill-0.3.8 docstring-parser-0.16 h5py-3.10.0 immutabledict-4.2.0 keras-3.1.1 mesh-tensorflow-0.1.21 ml-collections-0.1.1 ml-dtypes-0.3.2 multiprocess-0.70.16 mypy-extensions-1.0.0 namex-0.0.7 optree-0.11.0 pathspec-0.12.1 portalocker-2.8.2 pyglove-0.4.4 requests-unixsocket-0.3.0 rouge-score-0.1.2 sacrebleu-2.4.1 seqio-0.0.19 seqio-nightly-0.0.18.dev20240327 t5-0.9.4 tensorboard-2.16.2 tensorflow-2.16.1 tensorflow-text-2.16.1 tfds-nightly-4.9.2.dev202308090034 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/google/BIG-bench.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufS0pTzmB4FY",
        "outputId": "4a72cc60-7a2f-41ca-f133-feddddf90a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping kfac-jax as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+https://github.com/google-deepmind/kfac-jax@d3643a1ad85cd34ce9ec096a64c5a44708743217\n",
            "  Cloning https://github.com/google-deepmind/kfac-jax (to revision d3643a1ad85cd34ce9ec096a64c5a44708743217) to /tmp/pip-req-build-_32odvkk\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google-deepmind/kfac-jax /tmp/pip-req-build-_32odvkk\n",
            "  Running command git rev-parse -q --verify 'sha^d3643a1ad85cd34ce9ec096a64c5a44708743217'\n",
            "  Running command git fetch -q https://github.com/google-deepmind/kfac-jax d3643a1ad85cd34ce9ec096a64c5a44708743217\n",
            "  Running command git checkout -q d3643a1ad85cd34ce9ec096a64c5a44708743217\n",
            "  Resolved https://github.com/google-deepmind/kfac-jax to commit d3643a1ad85cd34ce9ec096a64c5a44708743217\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from kfac-jax==0.0.5) (1.4.0)\n",
            "Requirement already satisfied: immutabledict>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from kfac-jax==0.0.5) (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from kfac-jax==0.0.5) (1.25.2)\n",
            "Collecting distrax>=0.1.3 (from kfac-jax==0.0.5)\n",
            "  Downloading distrax-0.1.5-py3-none-any.whl (319 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from kfac-jax==0.0.5) (0.4.23)\n",
            "Requirement already satisfied: jaxlib>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from kfac-jax==0.0.5) (0.4.23+cuda12.cudnn89)\n",
            "Requirement already satisfied: dm-tree>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from kfac-jax==0.0.5) (0.1.8)\n",
            "Requirement already satisfied: optax>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from kfac-jax==0.0.5) (0.2.1)\n",
            "Requirement already satisfied: chex>=0.1.8 in /usr/local/lib/python3.10/dist-packages (from distrax>=0.1.3->kfac-jax==0.0.5) (0.1.86)\n",
            "Requirement already satisfied: tensorflow-probability>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from distrax>=0.1.3->kfac-jax==0.0.5) (0.23.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.7->kfac-jax==0.0.5) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.7->kfac-jax==0.0.5) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.7->kfac-jax==0.0.5) (1.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.8->distrax>=0.1.3->kfac-jax==0.0.5) (4.10.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.8->distrax>=0.1.3->kfac-jax==0.0.5) (0.12.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability>=0.15.0->distrax>=0.1.3->kfac-jax==0.0.5) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability>=0.15.0->distrax>=0.1.3->kfac-jax==0.0.5) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability>=0.15.0->distrax>=0.1.3->kfac-jax==0.0.5) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability>=0.15.0->distrax>=0.1.3->kfac-jax==0.0.5) (0.5.4)\n",
            "Building wheels for collected packages: kfac-jax\n",
            "  Building wheel for kfac-jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kfac-jax: filename=kfac_jax-0.0.5-py3-none-any.whl size=145934 sha256=255d2f401615bbf684313f15236db68b29092e4d4b47490d0abacf5dfa5a480c\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/00/92/f7138b019299f084dea5bdd41617ff971b8240abe1426cf70c\n",
            "Successfully built kfac-jax\n",
            "Installing collected packages: distrax, kfac-jax\n",
            "Successfully installed distrax-0.1.5 kfac-jax-0.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall kfac-jax -y\n",
        "!pip install git+https://github.com/google-deepmind/kfac-jax@d3643a1ad85cd34ce9ec096a64c5a44708743217"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-_ROVcv9DyV"
      },
      "outputs": [],
      "source": [
        "#@title Import Jax libraries\n",
        "\n",
        "import flax.linen as nn\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "\n",
        "import kfac_jax\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.colors as colors\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gZILq239Nin"
      },
      "outputs": [],
      "source": [
        "#@title The functional forms\n",
        "\n",
        "def count_params(params):\n",
        "  return sum([jnp.prod(jnp.arratarget(x.shape))\n",
        "              for x in jax.tree_util.tree_leaves(params)])\n",
        "\n",
        "def bnsl_dim(x, n_breaks, name):\n",
        "  #out = nn.Dense(1)(x) + nn.Dense(1, use_bias=False)(nn.softplus(nn.Dense(n_breaks)(x)))\n",
        "  out = nn.Dense(1)(x) + nn.Dense(1, use_bias=False)(nn.softplus(type(name, (nn.Dense,), {})(n_breaks)(x)))\n",
        "  return out\n",
        "\n",
        "class FunctionalForm(nn.Module):\n",
        "  \"\"\"BNSL operating in log-log space (i.e. inputs (and children of inputs) are never explicitly raised to a power).\"\"\"\n",
        "  n_breaks: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x, batch_train):\n",
        "    x = jnp.log(x)\n",
        "\n",
        "    offset = 1e-16\n",
        "    #offset = 0.0\n",
        "\n",
        "    x_train, y_train = batch_train\n",
        "    x_train, y_train = jnp.log(x_train), jnp.log(y_train + offset)\n",
        "\n",
        "    x_mean = jnp.mean(x_train, axis=0, keepdims=True)\n",
        "    x_std = jnp.std(x_train, axis=0, keepdims=True)\n",
        "    x_std = jnp.where(x_std == 0., 1., x_std)\n",
        "    x = (x - x_mean)/x_std\n",
        "\n",
        "    y_mean = jnp.mean(y_train)\n",
        "    u = jnp.ones_like(x[:,0]) * y_mean\n",
        "\n",
        "    eps_2 = jnp.log(1e-20)\n",
        "\n",
        "    eps_array = jnp.ones_like(x) * eps_2\n",
        "\n",
        "    x0 = jnp.zeros_like(x)\n",
        "\n",
        "    a = type(\"irr_ent\", (nn.Dense,), {})(1, use_bias=True)(x0)\n",
        "\n",
        "    _mbnsl = jnp.concatenate([\n",
        "          bnsl_dim(x, self.n_breaks, 'x'),\n",
        "          a,\n",
        "          eps_array,\n",
        "      ], axis=-1)\n",
        "\n",
        "    mbnsl = jax.scipy.special.logsumexp(_mbnsl, axis=-1, keepdims=False)\n",
        "\n",
        "    mbnsl = mbnsl + u\n",
        "\n",
        "    return jnp.exp(mbnsl)\n",
        "\n",
        "def functional_form__sle(params, _model, batch, batch_train):\n",
        "    x, y = batch\n",
        "    y_pred = _model.apply(params, x, batch_train)\n",
        "    pred, target = jnp.log(y_pred), jnp.log(y)\n",
        "    return jnp.square(pred - target)\n",
        "\n",
        "def functional_form__standard_le(params, _model, batch, batch_train):\n",
        "    x, y = batch\n",
        "    y_pred = _model.apply(params, x, batch_train)\n",
        "    pred, target = jnp.log(y_pred), jnp.log(y)\n",
        "\n",
        "    error = (pred - target) ** 2\n",
        "    err_mu = jnp.mean(error)\n",
        "    std_err = jnp.sqrt(err_mu + jnp.std(error) / (len(pred)**0.5)) - jnp.sqrt(err_mu)\n",
        "\n",
        "    return std_err\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BThCyHwnU1_X"
      },
      "outputs": [],
      "source": [
        "import bigbench\n",
        "bigbench_path = bigbench.__path__[0]\n",
        "#@title Imports and Setup\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "from bigbench.api import task\n",
        "from bigbench.api import results\n",
        "\n",
        "import os\n",
        "import dataclasses\n",
        "import json\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas\n",
        "import csv\n",
        "import pickle as pkl\n",
        "import ipywidgets\n",
        "#import random\n",
        "import time\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class PlotSettings:\n",
        "  marker: Optional[str] = None\n",
        "  palette: Optional[str] = None\n",
        "  linestyle: Optional[str] = None\n",
        "  label: Optional[str] = None\n",
        "\n",
        "DEFAULT_PLOT_SETTINGS = PlotSettings()\n",
        "PALETTES = ['crest', 'flare', 'rocket', 'mako', 'magma', 'viridis']\n",
        "LINESTYLES = ['-', '--', '-.', ':', 'solid', 'dashed', 'dashdot', 'dotted']\n",
        "MARKERS = ['.', 'o', 'x', 'd', '*', 'v', '+']\n",
        "\n",
        "\n",
        "with open(os.path.join(bigbench_path,'benchmark_tasks','task_human_eval.pkl'),'rb') as f:\n",
        "  eval_dicts = pkl.load(f)\n",
        "  HUMAN_EVAL_DICT = eval_dicts['average']\n",
        "  MAX_HUMAN_EVAL_DICT = eval_dicts['expert']\n",
        "\n",
        "PLOT_SETTINGS = {\n",
        "    'BIG-G T=0': PlotSettings(marker='d', palette='flare', linestyle='-', label='BIG-G'),\n",
        "    'BIG-G sparse': PlotSettings(marker='d', palette='flare', linestyle='dashed', label='BIG-G sparse'),\n",
        "    'GPT': PlotSettings(marker='o', palette='crest', linestyle='dashed', label='GPT'),\n",
        "    'BIG-G T=1': PlotSettings(marker='*', palette='crest', linestyle='-.', label='BIG-G T=1')\n",
        "}\n",
        "\n",
        "\n",
        "try:\n",
        "  shutil.rmtree(\"plots\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "os.mkdir(\"plots\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "  data_dict = {\n",
        "      \"name\": [],\n",
        "      \"rmsle_train\": [],\n",
        "      \"rmsle_extrap\": [],\n",
        "      \"rmsle_all\": [],\n",
        "      \"standard_le_train\": [],\n",
        "      \"standard_le_all\": [],\n",
        "  }\n",
        "\n",
        "  def plot_task(task_data: results.TaskData,\n",
        "                subtask: str,\n",
        "                metric: str,\n",
        "                shots: Optional[List[int]] = None,\n",
        "                model_families: Optional[List[str]] = None,\n",
        "                plot_settings: Optional[Dict[str, PlotSettings]] = None,\n",
        "                plot_human: bool = True,\n",
        "                normalize_mc_grade: bool = False,\n",
        "                plot_random: bool = True,\n",
        "                decreasing_score: bool = True):\n",
        "\n",
        "    task_name = task_data.name\n",
        "\n",
        "    if subtask not in task_data.subtasks:\n",
        "      raise ValueError(f'subtask {subtask} not found')\n",
        "\n",
        "    if metric not in task_data.data[subtask]:\n",
        "      raise ValueError(f'metric {metric} not found')\n",
        "\n",
        "    normalize_results = (metric == 'multiple_choice_grade' and\n",
        "                        normalize_mc_grade and\n",
        "                        task_data.preferred_metric[subtask] == 'multiple_choice_grade')\n",
        "\n",
        "    min_score = task_data.preferred_metric_low[subtask]\n",
        "    max_score = task_data.preferred_metric_high[subtask]\n",
        "\n",
        "    normalize_fn = lambda x: 100 * (x - min_score)/(max_score - min_score)\n",
        "\n",
        "    if model_families is None:\n",
        "      model_families = sorted(task_data.data[subtask][metric].keys())\n",
        "\n",
        "    for model_family in model_families:\n",
        "      if model_family not in task_data.data[subtask][metric]:\n",
        "        continue\n",
        "\n",
        "      if shots is None:\n",
        "        shots = task_data.data[subtask][metric][model_family].keys()\n",
        "\n",
        "      model_plot_settings = plot_settings.get(model_family, DEFAULT_PLOT_SETTINGS)\n",
        "\n",
        "      for shot in shots:\n",
        "\n",
        "        scores = task_data.scores(subtask=subtask, metric=metric, shots=shot,\n",
        "                                  model_family=model_family)\n",
        "        xdata = [x.params for x in scores]\n",
        "        ydata = [x.score for x in scores]\n",
        "\n",
        "        if normalize_results:\n",
        "          ydata = [normalize_fn(y) for y in ydata]\n",
        "\n",
        "        if decreasing_score:\n",
        "          if metric == (\"average_log_probability\" or \"log_likelihood\") or subtask == \"high_low_game\":\n",
        "            ydata = [-y for y in ydata]\n",
        "          else:\n",
        "            ydata = [(100.0 - y)/100 for y in ydata]\n",
        "\n",
        "        axes = plt.gca()\n",
        "\n",
        "        xdata = [np.dtype('float64').type(_x) for _x in xdata]\n",
        "\n",
        "        for end in [9]:\n",
        "\n",
        "          import gc; gc.collect()\n",
        "\n",
        "          start_time = time.time()\n",
        "\n",
        "          x_train = jnp.array(xdata[:end])\n",
        "          y_train = jnp.array(ydata[:end])\n",
        "\n",
        "          x_test = jnp.array(xdata[end:])\n",
        "          y_test = jnp.array(ydata[end:])\n",
        "\n",
        "          x_train = jnp.expand_dims(x_train, -1)\n",
        "          x_test = jnp.expand_dims(x_test, -1)\n",
        "\n",
        "          x_all = jnp.expand_dims(jnp.array(xdata), -1)\n",
        "          y_all = jnp.array(ydata)\n",
        "\n",
        "\n",
        "\n",
        "          #n_breaks = 2\n",
        "          n_breaks = 1\n",
        "\n",
        "          model = FunctionalForm(n_breaks=n_breaks)\n",
        "          params = model.init(random.PRNGKey(21), x_train, (x_train, y_train))\n",
        "\n",
        "          def loss(params, batch, offset=1e-16):\n",
        "\n",
        "            x, y = batch\n",
        "            y_pred = model.apply(params, x, batch)\n",
        "\n",
        "            pred, target = jnp.log(offset + y_pred), jnp.log(offset + y)\n",
        "\n",
        "            y_mean = jnp.mean(target)\n",
        "            y_std = jnp.std(target)\n",
        "            y_std = jnp.where(y_std == 0., 1., y_std)\n",
        "\n",
        "            target = target / y_std\n",
        "            pred = pred / y_std\n",
        "\n",
        "            kfac_jax.register_squared_error_loss(pred, target)\n",
        "\n",
        "            return jnp.mean(jnp.square(pred - target))\n",
        "          loss_and_grad = jax.value_and_grad(loss, argnums=0)\n",
        "\n",
        "          # using a second order optimizer makes training way faster\n",
        "          optimizer = kfac_jax.Optimizer(\n",
        "            value_and_grad_func=loss_and_grad,\n",
        "            l2_reg=0.0, # 1e-4,\n",
        "            value_func_has_aux=False,\n",
        "            value_func_has_state=False,\n",
        "            value_func_has_rng=False,\n",
        "            use_adaptive_learning_rate=True,\n",
        "            use_adaptive_momentum=True,\n",
        "            use_adaptive_damping=True,\n",
        "            initial_damping=1.0,\n",
        "            multi_device=False,\n",
        "          )\n",
        "\n",
        "          rng = random.PRNGKey(0)\n",
        "          rng, init_rng = random.split(rng)\n",
        "          opt_state = optimizer.init(params, init_rng, (x_train, y_train))\n",
        "\n",
        "          start_time = time.time()\n",
        "\n",
        "          # Fits in <1min on 1 GPU\n",
        "          best_params, best_loss = params, 1e6\n",
        "\n",
        "\n",
        "          for j in range(int(1e1)):\n",
        "            params = model.init(random.PRNGKey(j), x_train, (x_train, y_train))\n",
        "            rng = random.PRNGKey(j)\n",
        "            rng, init_rng = random.split(rng)\n",
        "            opt_state = optimizer.init(params, init_rng, (x_train, y_train))\n",
        "            for i in range(int(1e3)):\n",
        "              if i == 0:\n",
        "                #print(\"j =\", j)\n",
        "                pass\n",
        "              rng, step_rng = jax.random.split(rng)\n",
        "              params, opt_state, stats = optimizer.step(\n",
        "                  params, opt_state, step_rng, batch=(x_train, y_train), global_step_int=i)\n",
        "              if jnp.isnan(stats['loss']):\n",
        "                break\n",
        "              if (stats['loss'] < best_loss) and (stats['loss'] > 1e-12):\n",
        "                best_params = jax.tree_map(lambda x: jnp.array(x), params)\n",
        "                best_loss = stats['loss']\n",
        "                if i % 25 == 0:\n",
        "                  sle_train = functional_form__sle(best_params, model, (x_train, y_train), (x_train, y_train))\n",
        "                  sle_test = functional_form__sle(best_params, model, (x_test, y_test), (x_train, y_train))\n",
        "                  #print(f\"{jnp.sqrt(jnp.mean(sle_train)):.5e}\", f\"{jnp.sqrt(jnp.mean(sle_test)):.5e}\", f\"{best_loss:.5e}\", \"   \", f\"{(time.time() - start_time):.5e}\", \"\", j, i)\n",
        "\n",
        "          bc = best_params\n",
        "          print()\n",
        "          title = f'{subtask}'+\" \"+str(model_family)+\" \"+str(shot)+\"-shot\"\n",
        "          print(title)\n",
        "          print(bc)\n",
        "          print(\"time:\", time.time() - start_time)\n",
        "\n",
        "          sle_all = functional_form__sle(bc, model, (x_all, y_all), (x_train, y_train))\n",
        "          sle_train = functional_form__sle(bc, model, (x_train, y_train), (x_train, y_train))\n",
        "          sle_test = functional_form__sle(bc, model, (x_test, y_test), (x_train, y_train))\n",
        "\n",
        "          standard_le_all = functional_form__standard_le(bc, model, (x_all, y_all), (x_train, y_train))\n",
        "          standard_le_train = functional_form__standard_le(bc, model, (x_train, y_train), (x_train, y_train))\n",
        "\n",
        "          print(\"rmsle all:   \", jnp.sqrt(jnp.mean(sle_all)))\n",
        "          print(\"rmsle train: \", jnp.sqrt(jnp.mean(sle_train)))\n",
        "          print(\"rmsle test:  \", jnp.sqrt(jnp.mean(sle_test)))\n",
        "\n",
        "          print(\"standard_le_all:   \", standard_le_all)\n",
        "          print(\"standard_le_train: \", standard_le_train)\n",
        "\n",
        "          data_dict[\"name\"].append(title)\n",
        "          data_dict[\"rmsle_train\"].append(jnp.sqrt(jnp.mean(sle_train)))\n",
        "          data_dict[\"rmsle_extrap\"].append(jnp.sqrt(jnp.mean(sle_test)))\n",
        "          data_dict[\"rmsle_all\"].append(jnp.sqrt(jnp.mean(sle_all)))\n",
        "          data_dict[\"standard_le_train\"].append(standard_le_train)\n",
        "          data_dict[\"standard_le_all\"].append(standard_le_all)\n",
        "\n",
        "          points = 1024\n",
        "          x_tile = jnp.expand_dims(jnp.logspace(-1, 15, points), -1)\n",
        "\n",
        "          pred = model.apply(bc, x_tile, (x_train, y_train))\n",
        "\n",
        "          plt.plot(x_train, y_train, 'o', color='black', markersize=9.1)\n",
        "          plt.plot(x_test, y_test, 'o', color=[0.0, 0.835, 0.0], markersize=9.37, markerfacecolor=[0.0, 1.0, 0.0])\n",
        "          plt.plot(x_tile, pred, color=[1.0, 0.1275, 0.1275], linewidth=2.15, alpha=1.0)\n",
        "\n",
        "          plt.xlim(np.array(xdata).min()*.8,np.array(xdata).max()*1.3)\n",
        "          plt.ylim(np.array(ydata).min()*.9,np.array(ydata).max()*1.05)\n",
        "\n",
        "          axes.set_title(title, fontsize=16)\n",
        "          axes.set_xlabel(f'Number of Model Parameters', fontsize=12)\n",
        "          axes.set_ylabel(metric, fontsize=12)\n",
        "          plt.tick_params(axis='both', labelsize=12)\n",
        "\n",
        "          \"\"\"\n",
        "          plt.xscale('log')\n",
        "          plt.yscale('log')\n",
        "          #\"\"\"\n",
        "\n",
        "          #\"\"\"\n",
        "          axes.set_xscale('log')\n",
        "          axes.set_yscale('log')\n",
        "          #\"\"\"\n",
        "\n",
        "          plt.savefig('plots/'+str(initial_task)+\"__\"+str(model_family)+\"__\"+str(shot)+\"-shot\"+'.png', bbox_inches='tight')\n",
        "\n",
        "          plt.show()\n",
        "\n",
        "          #plt.close()\n",
        "          #plt.cla()\n",
        "          #plt.clf()\n",
        "\n",
        "    return None\n",
        "\n",
        "  #@title Load Data\n",
        "  TASK_DATA = results.load_results(path=os.path.join(bigbench_path,'benchmark_tasks'))\n",
        "  ALL_TASKS = sorted(TASK_DATA.keys())\n",
        "  #@title Select Task, Subtask, and Metric\n",
        "  print(\"ALL_TASKS: \", len(ALL_TASKS), ALL_TASKS)\n",
        "\n",
        "  ALL_TASKS = [_ for _ in ALL_TASKS if _ != 'training_on_test_set']\n",
        "\n",
        "  #ALL_TASKS = ALL_TASKS[-90:]\n",
        "  #ALL_TASKS = ALL_TASKS[:-90]\n",
        "\n",
        "  print(\"ALL_TASKS: \", len(ALL_TASKS), ALL_TASKS)\n",
        "\n",
        "  all_eval_metrics = []\n",
        "\n",
        "  header = ['task_name', 'model_family', 'metric', 'shots', 'func_form', 'num_points_for_fit', 'downstream_performance', 'mse_train', 'msle_train', 'mse_all', 'msle_all', 'se_extrap', 'sle_extrap', 'a', 'b', 'c', 'd', 'f', 'g', 'NaN']\n",
        "  with open('data.csv', 'a', encoding='UTF8') as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerow(header)\n",
        "\n",
        "      for t in ALL_TASKS:\n",
        "          initial_task = t\n",
        "          initial_subtask = initial_task\n",
        "          initial_metric = TASK_DATA[initial_task].preferred_metric[initial_subtask]\n",
        "\n",
        "          task_dropdown = ipywidgets.Dropdown(\n",
        "              options=ALL_TASKS, value=initial_task, description='Task')\n",
        "\n",
        "          subtask_dropdown = ipywidgets.Dropdown(\n",
        "              options=TASK_DATA[initial_task].subtasks,\n",
        "              value=initial_subtask,\n",
        "              description='Subtask')\n",
        "\n",
        "          metric_dropdown = ipywidgets.Dropdown(\n",
        "              options=sorted(TASK_DATA[initial_task].data[initial_subtask].keys()),\n",
        "              value=initial_metric,\n",
        "              description='Metric')\n",
        "\n",
        "          normalize_multiple_choice_checkbox = ipywidgets.Checkbox(\n",
        "              value=False,\n",
        "              description='Normalize multiple_choice_grade scores',\n",
        "              indent=False,\n",
        "          )\n",
        "\n",
        "          normalize_multiple_choice_label = ipywidgets.Label(\n",
        "              value=\"Select the following checkbox to normalize multiple_choice_grade \"\n",
        "              \"scores when the task's preferred score is multiple_choice_grade.\")\n",
        "\n",
        "          normalize_multiple_choice_label2 = ipywidgets.Label(\n",
        "              value=\"This will \"\n",
        "              \"make 0=random performance, and thus negative values may occur.\")\n",
        "\n",
        "          def task_update(*args):\n",
        "              subtask_dropdown.options = TASK_DATA[task_dropdown.value].subtasks\n",
        "              if task_dropdown.value in subtask_dropdown.options:\n",
        "                  subtask_dropdown.value = task_dropdown.value\n",
        "              else:\n",
        "                  subtask_dropdown.value = subtask_dropdown.options[0]\n",
        "\n",
        "          def subtask_update(*args):\n",
        "              metrics_list = sorted(\n",
        "                  TASK_DATA[task_dropdown.value].data[subtask_dropdown.value].keys())\n",
        "              preferred_metric = TASK_DATA[task_dropdown.value].preferred_metric[subtask_dropdown.value]\n",
        "              if preferred_metric in metrics_list:\n",
        "                  metrics_list.remove(preferred_metric)\n",
        "                  metrics_list = [preferred_metric] + metrics_list\n",
        "              metric_dropdown.options = metrics_list\n",
        "\n",
        "          task_dropdown.observe(task_update, 'value')\n",
        "          subtask_dropdown.observe(subtask_update, 'value')\n",
        "\n",
        "          #@title Plot\n",
        "          plt_task = task_dropdown.value\n",
        "          plt_subtask = subtask_dropdown.value\n",
        "          plt_metric = metric_dropdown.value\n",
        "          normalize_mc_grade = normalize_multiple_choice_checkbox.value\n",
        "\n",
        "          model_families = ['BIG-G sparse']\n",
        "          model_family = model_families[0]\n",
        "          try:\n",
        "            shots = TASK_DATA[plt_task].data[plt_subtask][plt_metric][model_family].keys()\n",
        "          except:\n",
        "            continue\n",
        "\n",
        "          for _s in shots:\n",
        "              data = plot_task(task_data=TASK_DATA[plt_task], subtask=plt_subtask, metric=plt_metric,\n",
        "                      model_families=model_families,\n",
        "                      shots=[_s],\n",
        "                      plot_settings=PLOT_SETTINGS,\n",
        "                      normalize_mc_grade=normalize_mc_grade)\n",
        "\n",
        "  df = pd.DataFrame(data_dict)\n",
        "  df.to_csv(\"error.csv\")\n",
        "\n",
        "  !zip -r plots.zip plots/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ztqp5vy54Yyi"
      },
      "outputs": [],
      "source": [
        "#!zip -r plots.zip plots/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw2XvKILbc7Y"
      },
      "outputs": [],
      "source": [
        "#df = pd.DataFrame(data_dict)\n",
        "#df.to_csv(\"error.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}